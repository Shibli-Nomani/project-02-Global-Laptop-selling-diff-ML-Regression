# ğŸ¢ project-02: Global Laptop Selling with Supervised Machine Learning Models (Regression)

<img width="423" alt="ml-regression" src="https://github.com/user-attachments/assets/5c975334-d65f-4a40-81e2-d6837ef6c52e" />



# ğŸ‘‡ Kaggle code Link :
https://www.kaggle.com/code/shiblinomani/project-02-global-laptop-selling-regression-ml
# ğŸ‘‡ Github Link :
https://github.com/Shibli-Nomani/project-02-Global-Laptop-selling-diff-ML-Regression/blob/main/project_02_global_laptop_selling_Regression_ML.ipynb
# ğŸ˜‰ About Dataset
https://www.kaggle.com/datasets/shiblinomani/global-laptop-price/data

# ãŠ—ï¸ Models
- ğŸ“ˆ Linear Regression
- ğŸŒ Ridge
- ğŸŒ³ Lasso
- ğŸŒ² ElasticNet
- ğŸ¤ DecisionTree
- ğŸ§  RandomForest
- ğŸš€ ExtraTree
- ğŸ§‘â€ğŸ’» KNN (K-Neighbors)
- ğŸŒŸ SVR (Support Vector Regressor)
- ğŸš€ LinearSVR (Linear Support Vector Regressor)
- âš¡ SGDRegressor (Stochastic Gradient Descent)
- ğŸ’» GaussianProcess (Gaussian Process Regressor)


# ğŸ¢ Summary 
The ExtraTree model leads with **99.97%** Train Accuracy and **88.29%** Test Accuracy, paired with a low **Mean Absolute Error (MAE) of 159.50.** RandomForest also performs strongly with 97.71% Train Accuracy and 87.04% Test Accuracy, showing an MAE of 166.30. On the lower end, ElasticNet (60.47% Test Accuracy) and GaussianProcess (-2846.32 Test Accuracy) exhibit poor test performance, with GaussianProcess suffering from severe overfitting. Models like LinearSVR, SGDRegressor, and Lasso show moderate performance, with Test Accuracies around 66%-67% and MAEs ranging from 285.05 to 287.53. Overall, the tree-based models (ExtraTree, RandomForest, DecisionTree) are the top performers for this dataset.

## Authors

- [@LinkedIn Khan MD Shibli Nomani](https://www.linkedin.com/in/khan-md-shibli-nomani-45445612b/)
