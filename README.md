# 🏢 project-02: Global Laptop Selling with Supervised Machine Learning Models (Regression)

<img width="423" alt="ml-regression" src="https://github.com/user-attachments/assets/5c975334-d65f-4a40-81e2-d6837ef6c52e" />



# 👇 Kaggle code Link :
https://www.kaggle.com/code/shiblinomani/project-02-global-laptop-selling-regression-ml
# 👇 Github Link :
https://github.com/Shibli-Nomani/project-02-Global-Laptop-selling-diff-ML-Regression/blob/main/project_02_global_laptop_selling_Regression_ML.ipynb
# 😉 About Dataset
https://www.kaggle.com/datasets/shiblinomani/global-laptop-price/data

# ㊗️ Models
- 📈 Linear Regression
- 🌐 Ridge
- 🌳 Lasso
- 🌲 ElasticNet
- 🤝 DecisionTree
- 🧠 RandomForest
- 🚀 ExtraTree
- 🧑‍💻 KNN (K-Neighbors)
- 🌟 SVR (Support Vector Regressor)
- 🚀 LinearSVR (Linear Support Vector Regressor)
- ⚡ SGDRegressor (Stochastic Gradient Descent)
- 💻 GaussianProcess (Gaussian Process Regressor)


# 🎢 Summary 
The ExtraTree model leads with **99.97%** Train Accuracy and **88.29%** Test Accuracy, paired with a low **Mean Absolute Error (MAE) of 159.50.** RandomForest also performs strongly with 97.71% Train Accuracy and 87.04% Test Accuracy, showing an MAE of 166.30. On the lower end, ElasticNet (60.47% Test Accuracy) and GaussianProcess (-2846.32 Test Accuracy) exhibit poor test performance, with GaussianProcess suffering from severe overfitting. Models like LinearSVR, SGDRegressor, and Lasso show moderate performance, with Test Accuracies around 66%-67% and MAEs ranging from 285.05 to 287.53. Overall, the tree-based models (ExtraTree, RandomForest, DecisionTree) are the top performers for this dataset.

## Authors

- [@LinkedIn Khan MD Shibli Nomani](https://www.linkedin.com/in/khan-md-shibli-nomani-45445612b/)
